{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369a111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"Single_Labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_dict(file_data,file):\n",
    "    \n",
    "    \"\"\"\n",
    "        file_data: dict which contains the writer id and line text per image\n",
    "        file: Name of the xml file from which data has been read\n",
    "        function of this function is to take in the dict and write it in the json file with the modified path\n",
    "        (\"a01-000u\\\\a01-000u\"-> a01-000u\\\\a01-000u-00.json\")\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    for number,dist in enumerate(file_data.items()):\n",
    "        path=os.path.join(base_path,file[17:-4]+\"-\"+f\"{number:02d}\")\n",
    "        with open(path+\".json\",\"w\") as file_json:\n",
    "            json.dump(dist,file_json)\n",
    "def xml_to_text(XML):\n",
    "    \"\"\"\n",
    "        XML: list of the xml files paths \n",
    "        read the  specific text and the writer id and call a writer-dict functions\n",
    "    \"\"\"\n",
    "    for xml_file in tqdm(XML):\n",
    "        tree = ET.parse(source=xml_file, parser=None)\n",
    "        root = tree.getroot()\n",
    "        file_data={}\n",
    "        writer_id=\"\"\n",
    "        for child in root.iter(\"form\"):\n",
    "            data=child.attrib\n",
    "            writer_id=(data[\"writer-id\"])\n",
    "\n",
    "\n",
    "        for child in root.iter(\"line\"):\n",
    "            data = child.attrib\n",
    "            file_data[data[\"text\"]]=writer_id\n",
    "\n",
    "            #file_data[xml_file[0]]=(data[\"text\"],writer_id)\n",
    "        writer_dict(file_data,xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296044c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file=sorted(glob.glob(\"line_data/Labels/*\"))\n",
    "print(\"Total XML Files=\", len(xml_file))\n",
    "len(xml_file)\n",
    "del xml_file[1230] # BAD SAMPLE\n",
    "xml_to_text(xml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491afaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Images=glob.glob(\"Line_data/Images/*/*/*\")\n",
    "print(\"Total number of the Images Files=\",len(Images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_xml=(sorted(glob.glob(base_path+\"/*\")))\n",
    "print(f\"Total number of json Files= {len(No_xml)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.join(base_path,Images[0].split(\"\\\\\")[-1][:-4]+\".json\")\n",
    "\"\"\"How to convert the path from .png to .json \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3627392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac767604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def Load_Image_Label(image_path):\n",
    "    # Open the image file\n",
    "    label=tuple()\n",
    "    json_path=os.path.join(base_path,image_path.split(\"\\\\\")[-1][:-4]+\".json\")\n",
    "    with open(json_path,\"r\") as json_file:\n",
    "        label=json.load(json_file)\n",
    "    img = imread(image_path, 0)\n",
    "    img = 255 - img\n",
    "    img_height, img_width = img.shape[0], img.shape[1]\n",
    "    n_repeats = int(np.ceil(150 / img_width))\n",
    "    padded_image = np.concatenate([img] * n_repeats, axis=1)\n",
    "    padded_image = padded_image[:15, :150]\n",
    "    resized_img = resize(padded_image, (150, 15))\n",
    "    return (resized_img,label)\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e51b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(Images[92])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d971858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "from cv2 import imread, resize,imshow,destroyAllWindows,waitKey\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as transforms\n",
    "\n",
    "import glob,os,sys\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import imread, resize\n",
    "class CustomImage:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_path=\"Single_Labels\",\n",
    "        img_dir=glob.glob(\"Line_data/Images/*/*/*\"),\n",
    "        transform=transforms.ToTensor(),\n",
    "    ):\n",
    "\n",
    "        self.base_path=base_path\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    def Load_Image_Label(self,image_path):\n",
    "        # Open the image file\n",
    "        label=tuple()\n",
    "        json_path=os.path.join(self.base_path,image_path.split(\"\\\\\")[-1][:-4]+\".json\")\n",
    "        with open(json_path,\"r\") as json_file:\n",
    "            label=json.load(json_file)\n",
    "        img = imread(image_path, 0)\n",
    "        img = 255 - img\n",
    "        img_height, img_width = img.shape[0], img.shape[1]\n",
    "        n_repeats = int(np.ceil(150 / img_width))\n",
    "        padded_image = np.concatenate([img] * n_repeats, axis=1)\n",
    "        padded_image = padded_image[:15, :150]\n",
    "        resized_img = resize(padded_image, (150, 15))\n",
    "        return (resized_img,label)\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        Image,Labels=self.Load_Image_Label(self.img_dir[idx])\n",
    "        return torch.tensor(Image, device=\"cpu\").float(), Labels\n",
    "        #return Image,Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded31406",
   "metadata": {},
   "outputs": [],
   "source": [
    " TextDatasetObj = CustomImage()\n",
    "    #no_workers = batch_size // num_example\n",
    "dataset = torch.utils.data.DataLoader(\n",
    "        TextDatasetObj, batch_size=2, shuffle=True, num_workers=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9d7cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"Single_Ladhjsdhdsbels\\\\a01-000u-00\"\n",
    "new_path = os.path.join(*path.split(\"\\\\\")[1:])\n",
    "print(new_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a38fb2",
   "metadata": {},
   "source": [
    "# for keys,value in file_data.items():\n",
    "    print({keys:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1f46a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_embd=torch.rand(2,5440\n",
    "                       )\n",
    "from torch import nn\n",
    "linear=nn.Linear(64*85,32)\n",
    "upsample=linear(char_embd)\n",
    "upsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd193da7",
   "metadata": {},
   "source": [
    "## import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load the XML data from a file\n",
    "tree = ET.parse(xml_file[0])\n",
    "\n",
    "# Get the root element\n",
    "root = tree.getroot()\n",
    "\n",
    "# Find the form element that contains the writer ID\n",
    "form = root.find(\".//form[@type='writer-id']\")\n",
    "print(form)\n",
    "# Get the writer ID attribute value from the form element\n",
    "writer_id = form.attrib['writer-id']\n",
    "\n",
    "# Find the line element with the specified ID\n",
    "line = root.find(\".//line[@id='a01-000u-00']\")\n",
    "\n",
    "# Get the text attribute value from the line element\n",
    "text = line.attrib['text']\n",
    "\n",
    "# Print the results\n",
    "print(\"Writer ID:\", writer_id)\n",
    "print(\"Text:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(line.get(\"writer-id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57b952",
   "metadata": {},
   "source": [
    "# Data Structure \n",
    "\n",
    "######  Image: words_data\\\\a01\\\\a01-000u\\\\a01-000u-00-00.png\n",
    "######  Label:labels\\\\a01-000u.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XML_TO_JSON():\n",
    "    label_dir = \"labels/\"\n",
    "    label_file = glob.glob(os.path.join(label_dir, \"*.xml\"))\n",
    "    for file in tqdm(label_file):\n",
    "        tree = ET.parse(source=file, parser=None)\n",
    "        root = tree.getroot()\n",
    "        data_dict = dict()\n",
    "        for child in root.iter(\"word\"):\n",
    "            data = child.attrib\n",
    "            data_dict[data[\"id\"]] = data[\"text\"]\n",
    "\n",
    "        with open(os.path.join(\"json/\", file[7:-4] + \".json\"), \"w\") as f:\n",
    "            json.dump(data_dict, f)\n",
    "            f.close()\n",
    "\n",
    "\n",
    "def data_set(path: str, data_name: str):\n",
    "    with open(path, \"rb\") as file:\n",
    "        grades = [x.strip() for x in file.readlines()]\n",
    "    print(\"No. of \" + data_name + \"_Files\", len(grades))\n",
    "    return grades\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e2b3f",
   "metadata": {},
   "source": [
    "# Path Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f524409",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = os.path.join(\"line_data/\")\n",
    "word_folder = glob.glob(base_folder+\"Images/*/*\")\n",
    "json_dict=glob.glob(base_folder+\"Labels/*\")\n",
    "print(\"base data length\",len(word_folder))\n",
    "print(\"json dict length\",(len(json_dict)))\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eacc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list()\n",
    "for i in json_dict:\n",
    "    with open(i) as json_file:\n",
    "        data.append((json.load(json_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f3552",
   "metadata": {},
   "source": [
    "##### creating dictonary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce570073",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=[]\n",
    "import json\n",
    "\n",
    "for lbl in data:\n",
    "    for words in lbl.values():\n",
    "        h.append(words)\n",
    "\n",
    "len(list(set(h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vocab=list(set(h))\n",
    "with open('words_vocab.txt','w') as file:\n",
    "    newline = os.linesep\n",
    "    for i in words_vocab:\n",
    "        file.write(newline+i)\n",
    "\n",
    "lis=list()\n",
    "with open('words_vocab.txt','r') as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        lis.append(line)\n",
    "string=[string for string in lis if string!=\"\"]\n",
    "len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc455c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1={\"a\":1,\"b\":3,\"c\":5}\n",
    "data2={\"l\":5,\"f\":0,\"h\":10}\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab(data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30616df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocab={' ',\n",
    " '!',\n",
    " '\"',\n",
    " '#',\n",
    " '&',\n",
    " \"'\",\n",
    " '(',\n",
    " ')',\n",
    " '*',\n",
    " '+',\n",
    " ',',\n",
    " '-',\n",
    " '.',\n",
    " '/',\n",
    " '0',\n",
    " '1',\n",
    " '2',\n",
    " '3',\n",
    " '4',\n",
    " '5',\n",
    " '6',\n",
    " '7',\n",
    " '8',\n",
    " '9',\n",
    " ':',\n",
    " ';',\n",
    " '?',\n",
    " 'A',\n",
    " 'B',\n",
    " 'C',\n",
    " 'D',\n",
    " 'E',\n",
    " 'F',\n",
    " 'G',\n",
    " 'H',\n",
    " 'I',\n",
    " 'J',\n",
    " 'K',\n",
    " 'L',\n",
    " 'M',\n",
    " 'N',\n",
    " 'O',\n",
    " 'P',\n",
    " 'Q',\n",
    " 'R',\n",
    " 'S',\n",
    " 'T',\n",
    " 'U',\n",
    " 'V',\n",
    " 'W',\n",
    " 'X',\n",
    " 'Y',\n",
    " 'Z',\n",
    " 'a',\n",
    " 'b',\n",
    " 'c',\n",
    " 'd',\n",
    " 'e',\n",
    " 'f',\n",
    " 'g',\n",
    " 'h',\n",
    " 'i',\n",
    " 'j',\n",
    " 'k',\n",
    " 'l',\n",
    " 'm',\n",
    " 'n',\n",
    " 'o',\n",
    " 'p',\n",
    " 'q',\n",
    " 'r',\n",
    " 's',\n",
    " 't',\n",
    " 'u',\n",
    " 'v',\n",
    " 'w',\n",
    " 'x',\n",
    " 'y',\n",
    " 'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "([[set(words) for char in lbl.values() for words in char] for lbl in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in json_dict:\n",
    "    data=read_json_files(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53141b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    #show_image\n",
    "    #img = mpimg.imread(image)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d46e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_folder)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00691059",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data={}\n",
    "count=0\n",
    "max_width=192\n",
    "for image,label in tqdm(zip(word_folder[:10],json_dict[:10])):\n",
    "        folder_data=list()\n",
    "        image_list=glob.glob(os.path.join(image,\"*.png\"))\n",
    "        data=read_json_files(label)\n",
    "        for index,s_image in enumerate(image_list):\n",
    "            tmp_dict=dict()\n",
    "            try:\n",
    "                img= Image.open(s_image)\n",
    "                hight,width=img.size\n",
    "                n_repeats = int(np.ceil(max_width/width))\n",
    "                repeated_image = np.tile(np.array(img), (1, n_repeats, 1))\n",
    "                concatenated_img = np.concatenate(repeated_image,axis=0)\n",
    "                # Convert the numpy array back to an image\n",
    "                #output_img = Image.fromarray(concatenated_img)\n",
    "                #plt.imshow(concatenated_img)\n",
    "                #print(concatenated_img.shape)\n",
    "                #print(f\"{type(img)=}\")\n",
    "                #img=img.resize((h,79))\n",
    "                tmp_dict[\"img\"]=concatenated_img\n",
    "                tmp_dict[\"label\"]=data[index]\n",
    "            except UnidentifiedImageError:\n",
    "                problem_files.append(s_image)\n",
    "            folder_data.append(tmp_dict)\n",
    "            c=str(count)\n",
    "\n",
    "        train_data[c]=folder_data\n",
    "        count+=1\n",
    "           \n",
    "count\n",
    "       \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"0\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5988c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=train_data[\"0\"][:][:1][0][\"img\"]\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da52629",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data={}\n",
    "count=1231\n",
    "problem_files=[]\n",
    "for image,label in tqdm(zip(word_folder[10:20],json_dict[10:20])):\n",
    "        folder_data=list()\n",
    "        image_list=glob.glob(os.path.join(image,\"*.png\"))\n",
    "        data=read_json_files(label)\n",
    "        for index,s_image in enumerate(image_list):\n",
    "            tmp_dict=dict()\n",
    "            try:\n",
    "                img=Image.open(s_image)\n",
    "                h,w=img.size\n",
    "                img=img.resize((h,79))\n",
    "\n",
    "                #tmp_dict[\"img\"]=img\n",
    "                tmp_dict[\"label\"]=data[index]\n",
    "                img.load()\n",
    "            except UnidentifiedImageError:\n",
    "                problem_files.append(s_image)\n",
    "            folder_data.append(tmp_dict)\n",
    "            c=str(count)\n",
    "        test_data[c]=folder_data\n",
    "        count+=1\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545cfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db658014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No. of samples in train data {len(train_data)} , No. of Samples in test_data {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e81ea",
   "metadata": {},
   "source": [
    "# dividing dataset into training and test phase\n",
    "#### total dataset 13551  test=2710   train=10841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ace00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set={\"train\":train_data,\"test\":test_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0512fd",
   "metadata": {},
   "source": [
    "# Creating pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb70362",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IMA-32_data_small.pickle\", \"wb\") as file:\n",
    "    pickle.dump(data_set, file, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e54ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd hand/files\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa7c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2849ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset():\n",
    "    def __init__(self, base_path =\"hand/files/IMA-32_data.pickle\" ,  num_examples = 15, target_transform=None):\n",
    "\n",
    "        self.NUM_EXAMPLES = num_examples\n",
    "  \n",
    "        #base_path = DATASET_PATHS\n",
    "        file_to_store = open(base_path, \"rb\")\n",
    "        self.IMG_DATA = pickle.load(file_to_store)['train']\n",
    "        self.IMG_DATA  = dict(list( self.IMG_DATA.items()))#[:NUM_WRITERS])\n",
    "        if 'None' in self.IMG_DATA.keys():\n",
    "            del self.IMG_DATA['None']\n",
    "        self.author_id = list(self.IMG_DATA.keys())\n",
    "\n",
    "        self.transform = get_transform(grayscale=True)\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.collate_fn = TextCollator()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.author_id)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "\n",
    "        NUM_SAMPLES = self.NUM_EXAMPLES\n",
    "\n",
    "\n",
    "        author_id = self.author_id[index]\n",
    "\n",
    "        self.IMG_DATA_AUTHOR = self.IMG_DATA[author_id]\n",
    "        random_idxs = np.random.choice(len(self.IMG_DATA_AUTHOR), NUM_SAMPLES, replace = True)\n",
    "\n",
    "        rand_id_real = np.random.choice(len(self.IMG_DATA_AUTHOR))\n",
    "        real_img = self.transform(self.IMG_DATA_AUTHOR[rand_id_real]['img'].convert('L'))\n",
    "        real_labels = self.IMG_DATA_AUTHOR[rand_id_real]['label'].encode()\n",
    "\n",
    "\n",
    "        imgs = [np.array(self.IMG_DATA_AUTHOR[idx]['img'].convert('L')) for idx in random_idxs]\n",
    "        labels = [self.IMG_DATA_AUTHOR[idx]['label'].encode() for idx in random_idxs]\n",
    "       \n",
    "        max_width = 192 #[img.shape[1] for img in imgs] \n",
    "        \n",
    "        imgs_pad = []\n",
    "        imgs_wids = []\n",
    "\n",
    "        for img in imgs:\n",
    "\n",
    "            img = 255 - img\n",
    "            img_height, img_width = img.shape[0], img.shape[1]\n",
    "            outImg = np.zeros(( img_height, max_width), dtype='float32')\n",
    "            outImg[:, :img_width] = img[:, :max_width]\n",
    "\n",
    "            img = 255 - outImg\n",
    "\n",
    "            imgs_pad.append(self.transform((Image.fromarray(img))))\n",
    "            imgs_wids.append(img_width)\n",
    "\n",
    "        imgs_pad = torch.cat(imgs_pad, 0)\n",
    "        \n",
    "\n",
    "        item = {'simg': imgs_pad, 'swids':imgs_wids, 'img' : real_img, 'label':real_labels,'img_path':'img_path', 'idx':'indexes', 'wcl':index}\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bb652",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open(\"IMA-32_data_small.pickle\", \"rb\")\n",
    "IMG_DATA = pickle.load(file_to_store)['train']\n",
    "IMG_DATA  = dict(list( IMG_DATA.items()))#[:NUM_WRITERS])\n",
    "if 'None' in IMG_DATA.keys():\n",
    "    del IMG_DATA['None']\n",
    "author_id = list(IMG_DATA.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_transform(grayscale=False, convert=True):\n",
    "\n",
    "    transform_list = []\n",
    "    if grayscale:\n",
    "        transform_list.append(transforms.Grayscale(1))\n",
    "\n",
    "    if convert:\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "        if grayscale:\n",
    "            transform_list += [transforms.Normalize((0.5,), (0.5,))]\n",
    "        else:\n",
    "            transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DATA_AUTHOR = IMG_DATA[\"5\"]\n",
    "random_idxs = np.random.choice(len(IMG_DATA_AUTHOR), 5, replace = True)\n",
    "rand_id_real = np.random.choice(len(IMG_DATA_AUTHOR))\n",
    "real_img = (IMG_DATA_AUTHOR[rand_id_real]['image'].convert('L'))\n",
    "real_labels = IMG_DATA_AUTHOR[rand_id_real]['label'].encode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319264db",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd60433",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6346ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=TextDataset(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec207c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"words_data/a02/a02-004/a02-004-00-01.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f49e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6bcaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Using cv2.imread() method\n",
    "# Using 0 to read image in grayscale mode\n",
    "img = cv2.imread(img_path, 0)\n",
    "  \n",
    "# Displaying the image\n",
    "print(img)\n",
    "black=1-img/255\n",
    "print((black.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow('balck', black)\n",
    "cv2.imshow('image', img)\n",
    "key = cv2.waitKey(0)#pauses for 3 seconds before fetching next image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b29531",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms((Image.fromarray(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"words_data/a02/a02-004/a02-004-00-01.png\"\n",
    "img=Image.open(img_path)\n",
    "h,w=img.size\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef36968",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = int(np.ceil(192/w))\n",
    "n_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_image = np.tile(np.array(img), (n_repeats))\n",
    "h,w=repeated_image.shape\n",
    "\n",
    "show_image(repeated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_image = np.concatenate([img] * 10, axis=0)\n",
    "\n",
    "    # Crop the image to the desired width\n",
    "padded_image = padded_image[:, :192]\n",
    "show_image(padded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(10,100).reshape(3,30)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[a]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66536c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=[b'not', b'of', b'the', b'of', b'Mr.', b'ineffectuay', b'and', b'the', b'Shelagh', b'of', b'is', b'terms', b',', b'unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "for i in str1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=b'unit000000000000000'.decode(\"utf-8\") \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d625c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(50, 50, max_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed76f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([i for i in str1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8998a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in str1:\n",
    "    print(embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "char='*'\n",
    "repeat=0\n",
    "for index,_ in enumerate(str1):\n",
    "    repeat=19-len(str1[index])\n",
    "    str1[index]=(str(str1[index].decode())+\"0\"*repeat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=[b'not0000000000000000',\n",
    " b'of00000000000000000',\n",
    " b'the0000000000000000',\n",
    " b'of00000000000000000',\n",
    " b'Mr.0000000000000000',\n",
    " b'ineffectuality00000',\n",
    " b'and0000000000000000',\n",
    " b'the0000000000000000',\n",
    " b'Shelagh000000000000',\n",
    " b'of00000000000000000',\n",
    " b'is00000000000000000',\n",
    " b'terms00000000000000',\n",
    " b',000000000000000000',\n",
    " b'unit000000000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401468cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(20-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d902d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={'o', 'u', ':', '6', 'g', 'r', '!', 'j', 'c', ',', 'y', 'f', 'b', 'm', '-', '9', '3', 'C', 't', 'v', ')', 'n', '.', 'E', '\"', 'S', \"'\", 'J', 'T', 'w', 'O', 'D', 'P', 'N', 's', 'I', 'h', ';', 'F', 'i', '?', 'k', 'a', 'p', 'W', 'A', 'z', 'M', 'G', 'e', '0', 'd', 'l'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder={data:i for i,data in enumerate(vocab)}\n",
    "decoder={i:data for i ,data in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626eddd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(label,encoder):\n",
    "    lst=[]\n",
    "    lst.append([encoder[char]for lbl in label for char in lbl])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding(str1,encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "a=[1,2,3,4,5]\n",
    "torch.FloatTensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1={'1':23,'3':45}\n",
    "eval(dic1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=['1',\"2\",\"3\"]\n",
    "eval(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c96512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "52d90d3cc821dd0beedd6e719dbdecc722c226b9d90ed1b663c34e1877f1142e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
